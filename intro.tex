%!TEX root =  lsa.tex
\section{Introduction}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
We consider the setting of constant stepsize linear stochastic approximation (LSA) algorithms with multiplicative $i.i.d$ noise and iterate averaging for finding the solution of linear systems based on noisy data. \todoc{Add blah blah about stochastic approximation: Citations, why care, ..}
The setting arises in applications in science and engineering, where the aim is to handle large volumes of high-dimensional data linear-in-the-dimension computation per time step. Two example applications which will use
as running examples are linear prediction with quadratic loss and using linear value functions to predict total reward 
of some fixed policy in reinforcement learning. \todoc{Add refs}
Recently, \citet{bachharder} achieved remarkable results in analyzing the expected loss of 
that arise in the solving linear least-squares prediction with squared loss and $i.i.d$ sampling.
According to this result, there exists a constant step-size such that for any problem where the noisy data is bounded by a known constant, the expected squared prediction error after $t$ updates is at most $\frac{C}{t}$ with a constant $C>0$ that depends \emph{only} on the bound on the data. \todoc{Dimension?} 
In particular, as opposed to many earlier results available in the literature \todoc{Add citations}, $C$ does \emph{not} depend on the conditioning of the underlying system, while the total runtime of the algorithm scales linearly with both $t$ and $n$. 
\todoc{Comment on: Was this known before for $O(n^2)$ or higher complexity algorithms?}

In this paper, we ask whether these ``remarkable" properties hold in our setting of general class of LSAs (other than the linear least-squares prediction setting). We are especially interested in linear value function approximation in reinforcement learning using temporal difference learning (TD) either from experience replay in a batch setting or solving linear systems using TD-style algorithms. \todoc{TD-style, or just TD?} \todoc{Later we need to comment on TD with eligibility traces and other variations of TD, e.g., new variants.}

Our proof technique for \cref{maintheorem} has been adopted from Appendix $B$ of \citet{bachharder}. \todoc{I believe it goes way back to the first proofs for stochastic approximation.} 
However, there are some critical differences which are listed below. \todoc{What is the difference to their earlier paper? We should also compare ourselves to that.}
\begin{itemize}
\item In the linear least-squares problem is considered by \citet{bachharder} and the random matrices involved are known to be symmetric positive definite. This enables \citet{bachharder} to define operators that act between spaces of \emph{symmetric} matrices and carry out the computations making use of such operators. In our case, the matrices are known only to be (laxly) positive definite, i.e., they lack symmetry. \todoc{We should point out after our analysis in which step the symmetry helps \citet{bachharder}. We should also make this somehow clear here if possible.}
Thus, the above approach does not work, and instead we have resort to an analysis that makes use of only the expected norms of the random matrices involved.
\item Another significant difference is that in linear least-squares, the ``noise'' has a favorable ``structure''. Again, due to the lack of symmetry, this favorable structure does not apply. \todoc{Again, after the analysis, we should point out how the structured noise would have helped. I am wondering whether a more graceful degradation should happen? Is this really all or nothing?}
\end{itemize}

