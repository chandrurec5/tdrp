\section{Problem Setup}\label{sec:prob}
%\input{restable}
We consider constant step size linear stochastic approximation (LSA) algorithms of the form
\begin{align}\label{lsa}
\theta_{t}=\theta_{t-1}+\alpha(g_t-H_t\theta_{t-1}),
\end{align}
where $\theta_t\in \R^n$, $\alpha>0$ is a positive step-size, $g_t\in \R^n$ and $H_t\in \R^{n\times n}$. The Polyak-Rupert average of the iterates $\theta_t$ in \eqref{lsa} is defined as
\begin{align}\label{rp} \tb_t\eqdef \frac{1}{t+1}\ous{\sum}{s=0}{t} \theta_s. \end{align}
We are interested in the behaviour of \eqref{lsa} under the following conditions.
\begin{assumption}\label{genlsa}
\begin{enumerate}
\item\label{mart} $H_t\eqdef H+M_t$, $g_t\eqdef g+N_t$, where $M_t\in \R^{n\times n}$ and $N_t\in \R^n$ are zero mean $i.i.d$ sequences, i.e., $\E[N_t]=0,\E[M_t]=0,~\forall t\geq 0$.
\item \label{noise} The noise sequences satisfy $\E[N_t^\top N_t]\leq \sigma_1^2$ and $\E[M_t^\top M_t]\leq \Sigma_2^2$, where $\sigma_1^2>0$ is a positive scalar and $\Sigma^2_2$ is a real symmetric positive definite matrix.
\item \label{mat} $H$ is such that $\forall x\in \R^n$, $\ip{x,Hx}>0$ and let $\ts=H^{-1}g\in\R^n$. Further, $\sigma_2^2$ is a scalar such that ${\ts}^\top\Sigma_2^2\ts\leq \sigma_2^2$ and $\sigma^2\eqdef\sigma_1^2+\sigma_2^2$.
\end{enumerate}
\end{assumption}
Here, $\ts$ is a parameter to be estimated that the LSA in \eqref{lsa} aims to compute from noisy data presented in the form of $g_t$ and $H_t$.\par
Our motivation to study constant step size LSA with RP-averaging stems from the fact that LSAs are common in applications such as temporal difference learning algorithms \cite{} in reinforcement learning (RL)\cite{}, solution to large scale linear systems \cite, and the linear least squares problem in \cite{}. In particular, constant step size and RP averaging has been shown to have `` amazing" properties in the case of linear least squares problem and we would like to investigate further as to whether these properties generalize to LSA.
\begin{example}[Temporal Difference Learning]
The Temporal Difference learning algorithm with a constant step size $\alpha>0$ is given by
\begin{align}\label{tdzero}
\theta_t=&\theta_{t-1}+\alpha \big(\phi(s_t) R(s_t)\nn\\&+ (\phi(s_t)\phi^\top(s_t)-\gamma \phi(s_t)\phi^\top(s'_t))\theta_{t-1}\big),
\end{align}
where are $s_t,s'_t\in S$ with $S$ being a finite set, $\phi(s)\in \R^n$ are the so called \emph{feature} vectors, $\gamma\in (0,1)$ is a given discount factor and $R\colon S\ra \R$ is map from S to reals. Here, $s_t$ are $i.i.d$ random variables distributed according to the law $s_t\sim \xi$ where $\xi$ is supported on $S$ and $s'_t\sim p(s_t,\cdot)$. The TD algorithm in \eqref{tdzero} can be cast in the general form as presented in \eqref{lsa}, by letting $g_t=\phi(s_t)R(s_t)$ and $H_t=\phi(s_t)\phi^\top(s_t)-\gamma \phi(s_t)\phi^\top(s'_t)$.
\end{example}

\textbf{Linear Stochastic Error Recursion (LSER)} The error dynamics for the LSA in \eqref{lsa} i.e., the dynamics of $e_t\eqdef\theta_t-\ts$ can be written as follows:
\begin{align}\label{errprelim}
&\theta_t-\ts=\theta_{t-1}-\ts+\alpha(g_t -H_t(\theta_t-\ts+\ts)),\text{~or}\nn\\
&e_t=(I-\alpha H_t)e_{t-1}+(N_t-M_t\ts).
\end{align}
In what follows we consider what we call linear stochastic error recursion (LSER) given by
\begin{align}\label{lsergen}
e_t=(I-\alpha H_t)e_{t-1}+\alpha \zeta_t,
\end{align}
where $\zeta_t\eqdef (N_t-M_t\ts)$.
\begin{theorem}\label{maintheorem}
Define $\rho_\alpha\eqdef \us{sup}{\norm{x}\leq 1}\E[x^\top (2H_t-\alpha H_tH_t)x]$. Let $\alpha_{\max}$ be such that $~\forall \alpha\in(0,\alpha_{\max})$ $\rho_{\alpha}>0$. Then, it follows that
\begin{align}
\E[\norm{H(\tb_t-\ts)}^2]\leq (1+4(\alpha\rho_{\alpha})^{-1}) (\alpha\rho_{\alpha})^{-1} \Big(\frac{\norm{\theta_0-\ts}^2}{(t+1)^2}+\frac{\alpha^2\sigma^2}{t+1} \Big)
\end{align}
\end{theorem}
\begin{proof}
\end{proof}
\textbf{Discussion}
\begin{enumerate}[leftmargin=*]
\item \textbf{Bias and Variance:} The means-squared error at $t$ is bounded by a sum of two terms. The first term is the bias term given by $\B=(1+4(\alpha\rho_{\alpha})^{-1}) (\alpha\rho_{\alpha})^{-1} \Big(\frac{\norm{\theta_0-\ts}^2}{(t+1)^2}\Big)$.  The \emph{Bias} term that captures the rate at which the initial condition $\norm{\theta_t-\ts}^2$ is forgotten. The second term is the \emph{Variance} given by $\V=(1+4(\alpha\rho_{\alpha})^{-1}) (\alpha\rho_{\alpha})^{-1} \Big(\frac{\alpha^2\sigma^2}{t+1} \Big)$. The variance term that captures the rate at which noise is rejected. The $\B$ and $\V$ terms capture two different sources of errors. To see this, note that in the absence of noise i.e., when $\zeta_t=0,~\forall t\geq 0$, we have $\E[\norm{H\eb_t}^2]=\B$ and in the presence of noise, i.e., $\zeta\neq 0,\forall t\geq 0$ and the perfect initial condition, i.e., $\theta_t=\ts$, we have $\E[\norm{H\eb_t}^2]=\V$.
\item \textbf{Faster Rates:} The bias term term decays $O(1/t^2)$ and the variance term decays $O(1/t)$, which are faster than the rates that can be achieved by a diminishing step size sequence recommended by standard stochastic approximation theory \cite{SA}. In particular, when the step sizes are decaying $O(1/t)$ one can only achieve an rate that is $O(1/t^\mu)$ where $\mu$ is the smallest real part of the eigenvalue of $H$. Thus the choice of a constant step size sequence with iterate averaging on top helps us to eliminate the effect of `ill' conditioning of $H$.
\item \textbf{Problem Dependent terms:} The choice of the step size is unfortunately problem dependent. To see this, the condition that $\rho_{\alpha}>0$ in \Cref{maintheorem} ensures that the expected spectral norm of $\E[(I-\alpha H_t)^\top(I-\alpha H_t)]$ is less than unity. And thus the range of $\alpha$ changes from problem to problem, an issue we further elaborate in \Cref{sec:stepprob}.
\item \textbf{Behaviour for extreme value of $\alpha$:} For smaller values of step size, i.e., $\alpha\approx 0$, the bias term blows up, due to the presence of $\alpha^{-1}$ term. This is due to the fact that the step sizes determine the learning rate and for smaller step sizes the learning rate is slower. However, in this case the noise term does not blow up, a fact that can appreciated by looking at \eqref{lsergen} where $\alpha$ is seen to multiply the noise term $\zeta_t$. In quantitative terms, we can see that the $\alpha^{-2}$ and $\alpha^2$ terms can each other. For larger values of $\alpha$ i.e., $\alpha\ra \alpha_{\max}$, the bounds blow up again, due to the fact that $\rho_{\alpha}\ra 0$ in this case. This is due to the fact that the effect of both noise and initial conditions decay with the contraction factor of $F_{t,i}$, which gets closer to unity as $\alpha\ra\alpha_{\max}$.
\end{enumerate}
