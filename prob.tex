%!TEX root =  lsa.tex
\section{Problem Setup and Main Result}\label{sec:prob}
%\input{restable}
We consider constant step size linear stochastic approximation (LSA) algorithms of the form
\begin{align}\label{lsa}
\theta_{t}=\theta_{t-1}+\alpha(g_t-H_t\theta_{t-1}),
\end{align}
where $\theta_t\in \R^n$, $\alpha>0$ is a positive step-size, $g_t\in \R^n$ and $H_t\in \R^{n\times n}$. The Polyak-Rupert average of the iterates $\theta_t$ in \eqref{lsa} is defined as
\begin{align}\label{rp} \tb_t\eqdef \frac{1}{t+1}\ous{\sum}{s=0}{t} \theta_s. \end{align}
We are interested in the behaviour of \eqref{lsa} under the following conditions.
\begin{assumption}\label{genlsa}
\begin{enumerate}
\item\label{mart} $H_t\eqdef H+M_t$, $g_t\eqdef g+N_t$, where $M_t\in \R^{n\times n}$ and $N_t\in \R^n$ are zero mean $i.i.d$ sequences, i.e., $\E[N_t]=0,\E[M_t]=0,~\forall t\geq 0$.
\item \label{noise} The noise sequences satisfy $\E[N_t^\top N_t]\leq \sigma_1^2$ and $\E[M_t^\top M_t]\leq \Sigma_2^2$, where $\sigma_1^2>0$ is a positive scalar and $\Sigma^2_2$ is a real symmetric positive definite matrix.
\item \label{mat} $H$ is such that $\forall x\in \R^n$, $\ip{x,Hx}>0$ and let $\ts=H^{-1}g\in\R^n$. Further, $\sigma_2^2$ is a scalar such that ${\ts}^\top\Sigma_2^2\ts\leq \sigma_2^2$ and $\sigma^2\eqdef\sigma_1^2+\sigma_2^2$.
\end{enumerate}
\end{assumption}
Here, $\ts$ is a parameter to be estimated that the LSA in \eqref{lsa} aims to compute from noisy data presented in the form of $g_t$ and $H_t$.\par
Our motivation to study constant step size LSA with RP-averaging stems from the fact that LSAs are common in applications such as temporal difference learning algorithms \cite{} in reinforcement learning (RL)\cite{}, solution to large scale linear systems \cite, and the linear least squares problem in \cite{}. In particular, constant step size and RP averaging has been shown to have `` amazing" properties in the case of linear least squares problem and we would like to investigate further as to whether these properties generalize to LSA.
\begin{example}[Temporal Difference Learning]
The Temporal Difference learning algorithm with a constant step size $\alpha>0$ is given by
\begin{align}\label{tdzero}
\theta_t=&\theta_{t-1}+\alpha \big(\phi(s_t) R(s_t)\nn\\&+ (\phi(s_t)\phi^\top(s_t)-\gamma \phi(s_t)\phi^\top(s'_t))\theta_{t-1}\big),
\end{align}
where are $s_t,s'_t\in S$ with $S$ being a finite set, $\phi(s)\in \R^n$ are the so called \emph{feature} vectors, $\gamma\in (0,1)$ is a given discount factor and $R\colon S\ra \R$ is map from S to reals. Here, $s_t$ are $i.i.d$ random variables distributed according to the law $s_t\sim \xi$ where $\xi$ is supported on $S$ and $s'_t\sim p(s_t,\cdot)$. The TD algorithm in \eqref{tdzero} can be cast in the general form as presented in \eqref{lsa}, by letting $g_t=\phi(s_t)R(s_t)$ and $H_t=\phi(s_t)\phi^\top(s_t)-\gamma \phi(s_t)\phi^\top(s'_t)$.
\end{example}

\textbf{Linear Stochastic Error Recursion (LSER)} The error dynamics for the LSA in \eqref{lsa} i.e., the dynamics of $e_t\eqdef\theta_t-\ts$ can be written as follows:
\begin{align}\label{errprelim}
&\theta_t-\ts=\theta_{t-1}-\ts+\alpha(g_t -H_t(\theta_t-\ts+\ts)),\text{~or}\nn\\
&e_t=(I-\alpha H_t)e_{t-1}+(N_t-M_t\ts).
\end{align}
In what follows we consider what we call linear stochastic error recursion (LSER) given by
\begin{align}\label{lsergen}
e_t=(I-\alpha H_t)e_{t-1}+\alpha \zeta_t,
\end{align}
where $\zeta_t\eqdef (N_t-M_t\ts)$.
\begin{theorem}\label{maintheorem}
Define $\rho_\alpha\eqdef \us{sup}{\norm{x}\leq 1}\E[x^\top (2H_t-\alpha H_tH_t)x]$. Let $\alpha_{\max}$ be such that $~\forall \alpha\in(0,\alpha_{\max})$ $\rho_{\alpha}>0$. Then, it follows that
\begin{align}
\begin{split}
\MoveEqLeft\E[\norm{H(\tb_t-\ts)}^2]\leq \\
&(1+4\frac1{\alpha\rho_{\alpha}}) \frac{1}{\alpha\rho_{\alpha}} \Big(\frac{\norm{\theta_0-\ts}^2}{(t+1)^2}+\frac{\alpha^2\sigma^2}{t+1} \Big)
\end{split}
\end{align}
\end{theorem}
