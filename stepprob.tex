\section{Step Size dependence on Problem Instance}\label{sec:stepprob}
We discussed in \Cref{sec:prob} that the maximum step size depends on the problem instance. The idea is to choose the step size that ensures stability of the recursion, which in turn translates to contraction properties of the product of random matrices. We now elaborate on two notions of contractions namely $(i)$ contraction per step, $(ii)$ contraction of the product.
\subsection{Contraction Per Time Step}
The proof of \Cref{maintheorem} uses the contraction per time step property. In such an analysis, the existence of problem independent $\alpha$ amounts the following formal condition stated in the form of \Cref{steptheorem}.
\begin{lemma}[Per Step Contraction]\label{steptheorem}
Let $\H$ be the space of $n\times n$ real matrices $H=(H_{ij}),i,j=1,\ldots,n$ with the absolute values of their entries bounded, i.e., $|H_{ij}|\leq B$ for some constant $B>0$. Let $\P$ be the space of distributions supported on $\M$ such that $~\forall x\in R^n, P\in \P,\E_{P}[x^\top H x] >0$ (where $H\in\H$ ). Then there exists an $\alpha_{\max}>0$ such that $\alpha\in(0,\alpha_{\max})$ implies $\us{\sup}{\norm{x}\leq 1,P\in\P}\E_{P}[\norm{(I-\alpha H)x}]< 1$.
\end{lemma}
\begin{example}[Counter Example for \Cref{steptheorem}]
Consider $\H=[-1,1]$ and $\P$ supported on $\{-1,1\}$ with $P(1)=\frac{1}{2}+\epsilon$ and $P(-1)=\frac{1}{2}-\epsilon$. Now we want translate the condition $\E_{P}[\norm{(I-\alpha H)x}]<1$
\begin{align}
\begin{split}
1-2\alpha\E[H]+\alpha^2 \E[H^2]<1\\
4\epsilon-\alpha>0\\
\end{split}
\end{align}
Since $\epsilon$ can be made arbitrarily close to $0$, $\alpha_{\max}=0$.
\end{example}
We now a case where $\alpha_{\max}>0$  can be achieved by restricting the support of $\P$ in \Cref{steptheorem}.
\begin{example}\label{rankonestep}
Let be $\H$ as in \Cref{steptheorem}, but define $\hat{\P}$ be the space of probability distributions supported only on rank-$1$ matrices expressed as $uu^\top$ for some $u\in \R^n$. Then there exists $\alpha_{\max}>0$ such that $\alpha\in(0,\alpha_{\max})$ implies $\us{\sup}{\norm{x}\leq 1,P\in\hat{\P}}\E_{P}[\norm{(I-\alpha H)x}]< 1$.\\
We now check for the condition as follows $\E_{P}[\norm{(I-\alpha H)x}]<1$
\begin{align}
\begin{split}
\E[x^\top(I-2\alpha H+\alpha^2 H^\top H)x]<1\\
\E[x(2 H- \alpha H^\top H)x]>0
\end{split}
\end{align}
We can now use the restriction on $\hat{\P}$, by observing that
\begin{align}
\E[x^\top H^\top Hx ]=\E[x^\top u^\top u u^\top u x]\leq B^2\E[x^\top H x]
\end{align}
Thus
\begin{align}
\begin{split}
\E[x(2 H- \alpha H^\top H)x]>2\E[x^\top H x]- B^2\alpha \E[x^\top H^x]>0,
\end{split}
\end{align}
Thus $\alpha_{\max}=\frac{2}{B^2}$.
\end{example}
\subsection{Contraction over time $t$}
The condition of contraction per time step is overly restrictive in the general case (other than the one presented in \Cref{rankonestep}). We can relax this condition and ask whether a weaker result in \Cref{multheorem} holds.
\begin{lemma}\label{multheorem}
Let $\H$ be the space of $n\times n$ real matrices $H=(H_{ij}),i,j=1,\ldots,n$ with the absolute values of their entries bounded, i.e., $|H_{ij}|\leq B$ for some constant $B>0$. Let $\P$ be the space of distributions supported on $\M$ such that $~\forall x\in R^n, P\in \P,\E_{P}[x^\top H x] >0$ (where $H\in\H$ ). Then there exists an $\alpha_{\max}>0$ such that $\alpha\in(0,\alpha_{\max})$ implies $\us{\sup}{\norm{x}\leq 1,P\in\P,t\geq 0}\E_{P}[\norm{(I-\alpha H)^tx}]< \infty$.
\end{lemma}
\textbf{Possible Counter example for \Cref{multheorem} in $\R$}
Consider $\H=[-1,1]$ and $\P$ supported on $\{-1,1\}$ with $P(1)=\frac{1}{2}+\epsilon$ and $P(-1)=\frac{1}{2}-\epsilon$. Note that
\begin{align*}
\E[\Pi_{i=1}^t (1-\alpha H_i)]&=\exp{\ous{\sum}{i=1}{t}\log(1-\alpha H_i)}\\
&\approx \exp{t\E[\log(1-\alpha H_i)]}
\end{align*}
Now the condition $\E[\Pi_{i=1}^t (1-\alpha H_i)]<\infty,$ where $H_i\sim P$ loosely translates to the following
\begin{align*}
\E[\log(1-\alpha H_i)]<0,
\end{align*}
which can be verified by noting that
\begin{align*}
\E[\log(1-\alpha H_i)]&=\E[(\frac{1}{2}+\epsilon)\log (1-\alpha)+(\frac{1}{2}-\epsilon)\log (1+\alpha)]\\
&=\frac{1}{2}\log(1-\alpha^2)+\epsilon(\log(1-\alpha)-\log(1+\alpha))\\
&<0
\end{align*}
\textbf{Possible Counter example for \Cref{multheorem} in $\R^2$}
Given any $\alpha$ the aim is to choose a distribution $P$ over $\H$ such that $\E_{P}[\norm{(I-\alpha H)^tx}]$ grows with $t$. In other words, given an $\alpha>0$, we are looking for a distribution $P'$ supported in the $\alpha$ neighbourhood of $I$ denoted by $\F$ such that $\E_{P'}[F^t]$ grows with $t$ (where $F\sim P'$). We now look at a possible suggestion for such a $P'$.\par
\begin{example}
Pick $F_1=\begin{bmatrix} 0 & 1-\beta_2 \\ 1+\beta_1& 0\\\end{bmatrix}^{\frac{1}{p}}$, $F_2=\begin{bmatrix} 0 & 1+\beta_1 \\ 1-\beta_2& 0\\\end{bmatrix}^{\frac{1}{p}}$, where $\beta_2>\beta_1$ such that $1+\frac{1}{2}(\beta_1-\beta_2)$. Let $P'$ be supported on $\{F_1,F_2\}$ with $P'(F_1)=\frac{1}{2}$ and $P'(F_2)=\frac{1}{2}$, and  $p$ is sufficiently large such that $F_1,F_2$ belong to the $\alpha$-neighbourhood of $I$. A possible way the random product can blow up is when products $F_2^pF_1^p$ occur in a contiguous stream. To see this,
\begin{align}
F_2^pF_1^p=\begin{bmatrix} (1+\beta_1) &0  \\ 0& (1-\beta_2)^2\\\end{bmatrix}
\end{align}
Thus $\norm{F_2^p F_1^p}>1$. However, such (i.e., $F_2^p F_1^p$) sequences have probability of occurance $\frac{1}{2^{2p}}$ is a sequence of length $2p$. Thus probability of them occuring quite often in a given random product is small.
\end{example}
